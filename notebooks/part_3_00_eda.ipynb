{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8bb3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "521c4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "\n",
    "profile = ProfileReport(df, title=\"Profiling Report\", explorative=True)\n",
    "profile.to_file(\"../docs/profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabe168",
   "metadata": {},
   "source": [
    "# Profiling Report Interpretation\n",
    "\n",
    "The full report can be found here: [`../docs/profiling_report.html`](../docs/profiling_report.html)\n",
    "\n",
    "## Summary Statistics\n",
    "\n",
    "From the summary statistics, we can see:\n",
    "- The training dataset has 31 variables (30 features + 1 target) and 7003 observations. The number of observations is much greater than the number of features, therefore no high-dimentional data issue yet.\n",
    "- Missing values are present, which need to be explored further.\n",
    "- There are no duplicated values.\n",
    "- Training data size is only 4.8 MB, which shouldn't cause any memory issues.\n",
    "\n",
    "<img src=\"../docs/images/summary_statistics.png\" alt=\"summary statistics\" width=\"300\" />\n",
    "\n",
    "## Target Distribution\n",
    "\n",
    "The target variable has 2 values, `0` and `1`, indicating a binary classification problem. The dataset is also imblanced, with class `1` taking up ~14% of total observations. Resampling may be useful to combat this issue. As we don't have a large number of observations, oversampling is preferred than undersampling. Common oversampling techniques with decent performance include `SMOTE` and `ADASYN`.\n",
    "\n",
    "<img src=\"../docs/images/target.png\" alt=\"target\" width=\"700\" />\n",
    "\n",
    "## Missing Values\n",
    "\n",
    "From the missing values chart, we can see that `Vicuna` is 100% missing, so we can drop it from the training dataset. It is a good idea to set up monitoring for Vicuna's missing percentage in the future in case it changes.\n",
    "\n",
    "<img src=\"../docs/images/missing_values.png\" alt=\"missing values\" width=\"800\" />\n",
    "\n",
    "`Tiglon` and `Wallaby` are both missing for ~50% with no particular pattern.\n",
    "\n",
    "`Tiglon` only has one constant value `False`. Applying one hot encoding should fix this issue without imputing for missing values.\n",
    "\n",
    "<img src=\"../docs/images/tiglon.png\" alt=\"tiglon\" width=\"700\" />\n",
    "\n",
    "`Wallaby` is a numerical feature. We can impute the missing values with `KNNImputer` or `SimpleImputer`.\n",
    "\n",
    "<img src=\"../docs/images/wallaby.png\" alt=\"wallaby\" width=\"700\" />\n",
    "\n",
    "## Features\n",
    "\n",
    "Out of the 30 features, 19 of them are numerical, 10 are categorical, 1 boolean (`Tiglon`) and 1 unsupported consisting of all null values (`Vicuna`).\n",
    "\n",
    "<img src=\"../docs/images/variable_types.png\" alt=\"variable types\" width=\"300\" />\n",
    "\n",
    "### Numerical Features\n",
    "\n",
    "The numerical features have wildly different scales, we could benefit from applying a scaler, such as `StandardScaler` or `MinMaxScaler`. \n",
    "\n",
    "There may also be outliers present, e.g. in features `Viper`, `Turkey`, but due to the lack of business context to determine if these values are invalid, I decided to keep them to be safe.\n",
    "\n",
    "### Categorical Features\n",
    "\n",
    "`Vulture` and `Warbler` have high cardinality issues with distinct categories of 40 and 83, respectively.\n",
    "<img src=\"../docs/images/vulture.png\" alt=\"vulture\" width=\"700\" />\n",
    "<img src=\"../docs/images/warbler.png\" alt=\"warbler\" width=\"700\" />\n",
    "\n",
    "`Tiger`, `Toad`, `Wildfowl`, `Wolf`, and `Wolverine` also present an uneven distribution of categories. Leaving them untreated may result in a sparse matrix after one-hot encoding and therefore affect model performance. Will consider to add a min_frequency rule during the encoding stage. Showing `Toad` as an example:\n",
    "<img src=\"../docs/images/toad.png\" alt=\"toad\" width=\"700\" />\n",
    "\n",
    "\n",
    "## Correlation\n",
    "\n",
    "There are high correlations between some features. I decided to not perform PCA or drop any correlated features, since 1) we don't have a high dimensionality problem and 2) the goal here is prediction rather than interpretation. As a result, we should steer away from linear algorithms that get impacted by multicollinearity, such as Logistic Regression or Naive Bayes.\n",
    "\n",
    "<img src=\"../docs/images/correlation.png\" alt=\"correlation\" width=\"700\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29fb555",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In summary, here are the preprocessing steps to perform before modelling:\n",
    "\n",
    "## Preprocessing Steps\n",
    "\n",
    "1. Drop `Vicuna`\n",
    "\n",
    "### Numerical Features\n",
    "\n",
    "2. Impute `Wallaby`'s missing values with an imputer, e.g. `KNNImputer` or `SimpleImputer`\n",
    "3. Scale all numerical features\n",
    "\n",
    "### Categorical Features\n",
    "\n",
    "4. One-hot encode categorical features, including `Tiglon`, with a min frequency rule\n",
    "\n",
    "### Target Resampling\n",
    "\n",
    "5. Add optional `target` resampling step to fix imbalanced dataset issue using `SMOTE` or `ADASYN`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
